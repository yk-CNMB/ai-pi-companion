# =======================================================================
# Pico AI Server - app.py (ç¤¾äº¤ç¾¤èŠç‰ˆ)
# åŠŸèƒ½: å…¨å±€å†å²è®°å½• | ç¤¾äº¤æ„ŸçŸ¥ | æœ¬åœ°è¯­éŸ³ | çº¯å‡€æ¨¡å¼
# =======================================================================
import os
import json
import uuid
import asyncio
import time
import glob
import shutil
import subprocess
import threading
import requests

import edge_tts
from flask import Flask, render_template, request, make_response, redirect, jsonify
from flask_socketio import SocketIO, emit, join_room
from google import genai

# --- 1. åˆå§‹åŒ– ---
app = Flask(__name__, static_folder='static')
app.config['SECRET_KEY'] = 'secret'
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')
SERVER_VERSION = str(int(time.time()))

# --- 2. ç›®å½•ä¸æ–‡ä»¶ ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
AUDIO_DIR = os.path.join(BASE_DIR, "static", "audio")
MODELS_DIR = os.path.join(BASE_DIR, "static", "live2d")
VOICES_DIR = os.path.join(BASE_DIR, "static", "voices")
PIPER_BIN = os.path.join(BASE_DIR, "piper_engine", "piper")
HISTORY_FILE = os.path.join(BASE_DIR, "chat_history.json") # å…¨å±€èŠå¤©è®°å½•

for d in [AUDIO_DIR, MODELS_DIR, VOICES_DIR]:
    if not os.path.exists(d): os.makedirs(d)

# --- 3. é…ç½®åŠ è½½ ---
CONFIG = {}
try:
    if os.path.exists("config.json"):
        with open("config.json", "r") as f: CONFIG = json.load(f)
except: pass

client = None
api_key = CONFIG.get("GEMINI_API_KEY") or os.getenv("GEMINI_API_KEY")
if api_key:
    try: client = genai.Client(api_key=api_key)
    except: pass

# --- 4. å…¨å±€è®°å¿†ç³»ç»Ÿ (æ ¸å¿ƒå‡çº§) ---
# å†…å­˜ä¸­çš„èŠå¤©è®°å½•ç¼“å­˜
GLOBAL_HISTORY = []
MAX_HISTORY_LEN = 50 # è®°ä½æœ€è¿‘ 50 å¥è¯ï¼Œå¤ªé•¿ä¼šæ¶ˆè€— Token

def load_global_history():
    global GLOBAL_HISTORY
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, "r") as f:
                GLOBAL_HISTORY = json.load(f)
            # æˆªæ–­æ—§çš„
            if len(GLOBAL_HISTORY) > MAX_HISTORY_LEN:
                GLOBAL_HISTORY = GLOBAL_HISTORY[-MAX_HISTORY_LEN:]
        except: GLOBAL_HISTORY = []

def save_global_history():
    try:
        with open(HISTORY_FILE, "w") as f:
            json.dump(GLOBAL_HISTORY, f, indent=2, ensure_ascii=False)
    except: pass

# å¯åŠ¨æ—¶åŠ è½½å†å²
load_global_history()

# è®°å½•æ¶ˆæ¯çš„è¾…åŠ©å‡½æ•°
def add_history(sender, text, role="user", emotion="NORMAL"):
    entry = {
        "timestamp": int(time.time()),
        "sender": sender,
        "text": text,
        "role": role, # user æˆ– pico
        "emotion": emotion
    }
    GLOBAL_HISTORY.append(entry)
    # ä¿æŒé•¿åº¦é™åˆ¶
    if len(GLOBAL_HISTORY) > MAX_HISTORY_LEN:
        GLOBAL_HISTORY.pop(0)
    # å¼‚æ­¥ä¿å­˜ï¼ˆthreadingæ¨¡å¼ä¸‹ç›´æ¥ä¿å­˜ä¹Ÿæ²¡äº‹ï¼Œé‡ä¸å¤§ï¼‰
    save_global_history()
    return entry

# --- 5. æ¨¡å‹ç®¡ç† ---
CURRENT_MODEL = {"id": "default", "name": "Default", "persona": "", "voice": "zh-CN-XiaoxiaoNeural", "rate": "+0%", "pitch": "+0Hz", "scale": 0.5, "x": 0.5, "y": 0.5}

def get_model_config(mid):
    p = os.path.join(MODELS_DIR, mid, "config.json")
    d = {"persona":f"ä½ æ˜¯{mid}ã€‚", "voice":"zh-CN-XiaoxiaoNeural", "rate":"+0%", "pitch":"+0Hz", "scale":0.5, "x":0.5, "y":0.5}
    if os.path.exists(p):
        try: d.update(json.load(open(p))) 
        except: pass
    return d

def save_model_config(mid, data):
    p = os.path.join(MODELS_DIR, mid, "config.json")
    curr = get_model_config(mid); curr.update(data)
    with open(p, "w", encoding="utf-8") as f: json.dump(curr, f, indent=2)
    return curr

def scan_models():
    ms = []
    for j in glob.glob(os.path.join(MODELS_DIR, "**", "*.model3.json"), recursive=True):
        mid = os.path.basename(os.path.dirname(j))
        cfg = get_model_config(mid)
        ms.append({"id": mid, "name": mid.capitalize(), "path": "/"+os.path.relpath(j, BASE_DIR).replace("\\","/"), **cfg})
    return sorted(ms, key=lambda x: x['name'])

def init_model():
    global CURRENT_MODEL
    ms = scan_models()
    t = next((m for m in ms if "hiyori" in m['id'].lower()), ms[0] if ms else None)
    if t: CURRENT_MODEL = t
init_model()

# --- 6. TTS ---
def run_piper_tts(text, model_file, output_path):
    model_path = model_file if os.path.isabs(model_file) else os.path.join(VOICES_DIR, model_file)
    if not os.path.exists(PIPER_BIN) or not os.path.exists(model_path): return False
    try:
        cmd = [PIPER_BIN, "--model", model_path, "--output_file", output_path]
        subprocess.run(cmd, input=text.encode('utf-8'), check=True, capture_output=True)
        return True
    except: return False

def bg_tts(text, voice, rate, pitch, sid=None):
    clean = re.sub(r'\[(.*?)\]', '', text).strip()
    if not clean: return
    fname = f"{uuid.uuid4()}"
    success = False; url = ""
    
    if voice.endswith(".onnx"):
         if run_piper_tts(clean, voice, os.path.join(AUDIO_DIR, f"{fname}.wav")):
             success=True; url=f"/static/audio/{fname}.wav"

    if not success:
        safe_voice = voice if ("Neural" in voice) else "zh-CN-XiaoxiaoNeural"
        try:
            edge_tts.Communicate(clean, safe_voice, rate=rate, pitch=pitch).save_sync(os.path.join(AUDIO_DIR, f"{fname}.mp3"))
            success=True; url=f"/static/audio/{fname}.mp3"
        except: pass

    if success:
        # å¹¿æ’­ç»™æ‰€æœ‰äººå¬ï¼ç›´æ’­é—´é‡Œå¤§å®¶éƒ½èƒ½å¬åˆ° AI è¯´è¯
        socketio.emit('audio_response', {'audio': url}, to='lobby')

# --- 7. è·¯ç”± ---
@app.route('/')
def idx(): return redirect(url_for('pico_v', v=SERVER_VERSION))
@app.route('/pico')
def pico_legacy(): return redirect(url_for('pico_v', v=SERVER_VERSION))
@app.route('/pico/<v>')
def pico_v(v): return render_template('chat.html')

# --- 8. SocketIO (ç¤¾äº¤æ ¸å¿ƒ) ---
users = {}
chatroom_chat = None

def get_ai_response(prompt, history_context):
    if not client: return "[ç³»ç»Ÿ] AI æœªè¿æ¥"
    try:
        # é‡æ–°æ„å»º Chat Sessionï¼Œå¸¦å…¥å†å²èƒŒæ™¯
        # è¿™é‡Œçš„ system_instruction åŒ…å«äº†äººè®¾ + è¿‘æœŸèŠå¤©è®°å½•
        system_prompt = f"{CURRENT_MODEL['persona']}\n\nã€è¿‘æœŸèŠå¤©è®°å½•(ä¾›å‚è€ƒï¼Œè¯·è®°ä½è¿™äº›ä¿¡æ¯ä»¥å›ç­”ç”¨æˆ·å…³äºå…¶ä»–äººçš„é—®é¢˜)ã€‘:\n{history_context}"
        
        chat = client.chats.create(model="gemini-2.5-flash", config={"system_instruction": system_prompt})
        resp = chat.send_message(prompt)
        return resp.text
    except Exception as e: return f"[Error] {e}"

@socketio.on('connect')
def on_connect(): emit('server_ready', {'status': 'ok'})

@socketio.on('login')
def on_login(d):
    u = d.get('username','').strip() or "åŒ¿å"
    users[request.sid] = {"username": u, "is_admin": False}
    join_room('lobby')
    
    emit('login_success', {'username': u, 'current_model': CURRENT_MODEL})
    
    # ã€å…³é”®ã€‘æŠŠæœåŠ¡å™¨å­˜çš„å†å²è®°å½•å‘ç»™æ–°ç”¨æˆ·
    # è¿™æ ·Aä¸€è¿›æ¥å°±èƒ½çœ‹åˆ° YK ä¹‹å‰è¯´äº†ä»€ä¹ˆ
    emit('history_sync', GLOBAL_HISTORY)
    
    sys_msg = f"ğŸ‰ æ¬¢è¿ {u} è¿›å…¥ç›´æ’­é—´ï¼"
    emit('system_message', {'text': sys_msg}, to='lobby')
    add_history("ç³»ç»Ÿ", sys_msg, "system") # è®°å½•è¿›åœº

@socketio.on('message')
def on_message(d):
    sid = request.sid
    if sid not in users: return
    sender = users[sid]['username']
    msg = d['text']
    # ç”¨æˆ·çš„ç§æœ‰è®°å¿† (Client -> Server)
    private_mems = d.get('memories', [])
    
    if "/ç®¡ç†å‘˜" in msg:
        if sender.lower() == "yk": users[sid]['is_admin']=True; emit('admin_unlocked'); return
    
    # 1. å¹¿æ’­ç”¨æˆ·æ¶ˆæ¯ç»™æ‰€æœ‰äºº
    emit('chat_message', {'text': msg, 'sender': sender}, to='lobby')
    add_history(sender, msg, "user") # å­˜å…¥å†å²

    # 2. æ„å»ºä¸Šä¸‹æ–‡ (Social Context)
    # å°†æœ€è¿‘çš„èŠå¤©è®°å½•æ‹¼æ¥æˆæ–‡æœ¬ï¼Œå–‚ç»™ AI
    # æ ¼å¼: [YK]: å¤§å®¶å¥½ / [Pico]: ä½ å¥½å‘€
    recent_context = "\n".join([f"[{h['sender']}]: {h['text']}" for h in GLOBAL_HISTORY[-20:]])
    
    # 3. ç§æœ‰è®°å¿†æ³¨å…¥
    # åªæœ‰å½“å‰æé—®è€…(sender)çš„ç§æœ‰è®°å¿†ä¼šè¢«åŠ è¿›å»
    memory_context = ""
    if private_mems:
        memory_context = f"\nã€{sender}çš„ç§æœ‰å¤‡æ³¨(ä»…ä½ çŸ¥é“)ã€‘: {', '.join(private_mems)}"

    # 4. ç”Ÿæˆå›ç­”
    full_prompt = f"[{sender} è¯´]: {msg}{memory_context}"
    
    # å¼‚æ­¥å¤„ç† AI å›å¤
    threading.Thread(target=handle_ai_response, args=(full_prompt, recent_context, sender)).start()

def handle_ai_response(prompt, context, sender):
    # AI æ€è€ƒ
    reply_text = get_ai_response(prompt, context)
    
    # è§£æè¡¨æƒ…
    emo='NORMAL'
    match = re.search(r'\[(HAPPY|ANGRY|SAD|SHOCK|NORMAL)\]', reply_text)
    clean_text = reply_text.replace(match.group(0), '').strip() if match else reply_text
    if match: emo = match.group(1)
    
    # å¹¿æ’­ AI å›å¤
    socketio.emit('response', {'text': clean_text, 'sender': CURRENT_MODEL['name'], 'emotion': emo}, to='lobby')
    
    # å­˜å…¥å†å²
    add_history(CURRENT_MODEL['name'], clean_text, "pico", emo)
    
    # åˆæˆè¯­éŸ³
    bg_tts(clean_text, CURRENT_MODEL['voice'], CURRENT_MODEL['rate'], CURRENT_MODEL['pitch'])

# --- å…¶ä»–æ¥å£ (ä¿æŒä¸å˜) ---
@socketio.on('get_studio_data')
def on_get_data():
    voices = [{"id":"zh-CN-XiaoxiaoNeural","name":"â˜ï¸ æ™“æ™“"},{"id":"en-US-AnaNeural","name":"â˜ï¸ Ana"}]
    if os.path.exists(VOICES_DIR):
        for onnx in glob.glob(os.path.join(VOICES_DIR, "*.onnx")):
            name = os.path.basename(onnx).replace(".onnx", "")
            if os.path.exists(os.path.join(VOICES_DIR, f"{name}.txt")): 
                try: name = open(os.path.join(VOICES_DIR, f"{name}.txt")).read().strip()
                except: pass
            voices.append({"id": os.path.basename(onnx), "name": f"ğŸ  {name}"})
    emit('studio_data', {'models': scan_models(), 'current_id': CURRENT_MODEL['id'], 'voices': voices})

@socketio.on('switch_model')
def on_switch(d):
    global CURRENT_MODEL
    t = next((m for m in scan_models() if m['id'] == d['id']), None)
    if t: CURRENT_MODEL = t; emit('model_switched', CURRENT_MODEL, to='lobby')

@socketio.on('save_settings')
def on_save_settings(d):
    global CURRENT_MODEL
    if not users.get(request.sid, {}).get('is_admin'): return
    try: d['scale']=float(d['scale']); d['x']=float(d['x']); d['y']=float(d['y'])
    except: pass
    updated = save_model_config(d['id'], d)
    if CURRENT_MODEL['id'] == d['id']: CURRENT_MODEL.update(updated); emit('model_switched', CURRENT_MODEL, to='lobby')
    emit('toast', {'text': 'âœ… ä¿å­˜æˆåŠŸ'})
# (ä¸‹è½½/ä¸Šä¼ æ¥å£ä¿æŒä¸å˜ï¼Œçœç•¥)

if __name__ == '__main__':
    socketio.run(app, host='0.0.0.0', port=5000)
