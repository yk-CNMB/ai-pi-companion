# =======================================================================
# Pico AI Server - "Heavy Armor" Stable Edition
# æ¢å¤äº†å®Œæ•´çš„é”™è¯¯å¤„ç†ã€ç‹¬ç«‹äº‹ä»¶å¾ªç¯å’Œæ–‡ä»¶ç®¡ç†é€»è¾‘
# =======================================================================
import os
import json
import uuid
import time
import glob
import shutil
import re
import zipfile
import threading
import requests
import urllib.parse
import base64
import asyncio
import logging

# åªä½¿ç”¨çº¯ Python åº“ï¼Œä¸ä¾èµ–ç³»ç»Ÿåº•å±‚éŸ³é¢‘åº“
import edge_tts

from flask import Flask, render_template, request, make_response, redirect, url_for, jsonify
from flask_socketio import SocketIO, emit, join_room, leave_room
from google import genai
from google.genai import types
from werkzeug.utils import secure_filename

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

app = Flask(__name__, static_folder='static')
app.config['SECRET_KEY'] = 'pico_secret_key_2025'
app.config['MAX_CONTENT_LENGTH'] = 50 * 1024 * 1024  # 50MB ä¸Šä¼ é™åˆ¶

# å¢åŠ  buffer size é˜²æ­¢å›¾ç‰‡ä¼ è¾“æ–­è¿ï¼Œå¯ç”¨ ping/pong ä¿æ´»
socketio = SocketIO(app, 
    cors_allowed_origins="*", 
    async_mode='threading', 
    ping_timeout=60, 
    ping_interval=25,
    max_http_buffer_size=10*1024*1024
)

SERVER_VERSION = str(int(time.time()))

# --- ç›®å½•ç»“æ„åˆå§‹åŒ– ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
AUDIO_DIR = os.path.join(BASE_DIR, "static", "audio")
MODELS_DIR = os.path.join(BASE_DIR, "static", "live2d")
BG_DIR = os.path.join(BASE_DIR, "static", "backgrounds")
STATE_FILE = os.path.join(BASE_DIR, "server_state.json")

# ç¡®ä¿æ‰€æœ‰ç›®å½•å­˜åœ¨
for d in [AUDIO_DIR, MODELS_DIR, BG_DIR]:
    if not os.path.exists(d):
        os.makedirs(d)
        logging.info(f"Created directory: {d}")

# --- å…¨å±€é…ç½® ---
CONFIG = {
    "GEMINI_API_KEY": "",
    "TTS_VOICE": "zh-CN-XiaoxiaoNeural", # é»˜è®¤å¥½å¬çš„ä¸­æ–‡å¥³å£°
    "TTS_RATE": "+0%",
    "TTS_PITCH": "+0Hz"
}

# å°è¯•åŠ è½½é…ç½®æ–‡ä»¶
try:
    if os.path.exists("config.json"):
        with open("config.json", "r", encoding='utf-8') as f: 
            # è¿‡æ»¤æ³¨é‡Šè¡Œ
            content = "\n".join([line for line in f.readlines() if not line.strip().startswith("//")])
            CONFIG.update(json.loads(content))
            logging.info("Config loaded successfully.")
except Exception as e:
    logging.error(f"Config load error: {e}")

# åˆå§‹åŒ– Gemini å®¢æˆ·ç«¯
client = None
api_key = CONFIG.get("GEMINI_API_KEY")
if api_key and "AIza" in api_key:
    try:
        client = genai.Client(api_key=api_key)
        logging.info("Gemini Client initialized.")
    except Exception as e:
        logging.error(f"Gemini init failed: {e}")

# --- ç³»ç»ŸæŒ‡ä»¤ ---
EMOTION_INSTRUCTION = """
ã€ç³»ç»ŸæŒ‡ä»¤ã€‘
ä½ æ˜¯ä¸€ä¸ªæ‹¥æœ‰ Live2D å½¢è±¡çš„è™šæ‹Ÿä¸»æ’­ã€‚
1. è¯·åœ¨æ¯æ¬¡å›å¤çš„å¼€å¤´ï¼Œå¿…é¡»æ˜ç¡®æ ‡è®°ä½ å½“å‰çš„å¿ƒæƒ…æ ‡ç­¾ã€‚
2. æ ‡ç­¾å¿…é¡»æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼š[HAPPY], [ANGRY], [SAD], [SHOCK], [NORMAL]ã€‚
3. æ ‡ç­¾åç´§è·Ÿä½ çš„å›å¤å†…å®¹ã€‚

ä¾‹å¦‚ï¼š
[HAPPY] å“‡ï¼è¿™ä¹Ÿå¤ªæ£’äº†å§ï¼
[ANGRY] å“¼ï¼Œæˆ‘ä¸ç†ä½ äº†ã€‚
[SHOCK] çœŸçš„å‡çš„ï¼Ÿå®Œå…¨æ²¡æƒ³åˆ°ï¼
"""

# --- å…¨å±€çŠ¶æ€ç®¡ç† ---
GLOBAL_STATE = {
    "current_model_id": "default",
    "current_background": "",
    "chat_history": []
}

def load_state():
    global GLOBAL_STATE
    if os.path.exists(STATE_FILE):
        try:
            with open(STATE_FILE, 'r', encoding='utf-8') as f:
                saved = json.load(f)
                GLOBAL_STATE.update(saved)
                # åªä¿ç•™æœ€è¿‘ 100 æ¡å†å²
                GLOBAL_STATE["chat_history"] = GLOBAL_STATE["chat_history"][-100:]
        except Exception as e:
            logging.error(f"Load state error: {e}")

def save_state():
    try:
        with open(STATE_FILE, 'w', encoding='utf-8') as f:
            json.dump(GLOBAL_STATE, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logging.error(f"Save state error: {e}")

load_state()

# å½“å‰æ¨¡å‹é…ç½®ç¼“å­˜
CURRENT_MODEL = {
    "id": "default", 
    "path": "", 
    "persona": "", 
    "voice": "zh-CN-XiaoxiaoNeural", 
    "rate": "+0%", 
    "pitch": "+0Hz", 
    "scale": 0.5, 
    "x": 0.5, 
    "y": 0.5
}

def get_model_config(mid):
    """è¯»å–ç‰¹å®šæ¨¡å‹çš„ config.json"""
    p = os.path.join(MODELS_DIR, mid, "config.json")
    # é»˜è®¤å€¼
    default_persona = f"ä½ æ˜¯{mid}ã€‚{EMOTION_INSTRUCTION}"
    d = {
        "persona": default_persona, 
        "voice": "zh-CN-XiaoxiaoNeural", 
        "rate": "+0%", 
        "pitch": "+0Hz", 
        "scale": 0.5, 
        "x": 0.5, 
        "y": 0.5
    }
    if os.path.exists(p):
        try:
            with open(p, "r", encoding="utf-8") as f: 
                loaded = json.load(f)
                # ç¡®ä¿äººè®¾åŒ…å«æƒ…æ„ŸæŒ‡ä»¤
                if 'persona' in loaded and EMOTION_INSTRUCTION not in loaded['persona']:
                    loaded['persona'] += EMOTION_INSTRUCTION
                d.update(loaded)
        except: pass
    return d

def save_model_config(mid, data):
    """ä¿å­˜ç‰¹å®šæ¨¡å‹çš„é…ç½®"""
    p = os.path.join(MODELS_DIR, mid, "config.json")
    curr = get_model_config(mid)
    curr.update(data)
    try:
        with open(p, "w", encoding="utf-8") as f:
            json.dump(curr, f, indent=2, ensure_ascii=False)
    except: pass
    return curr

def scan_models():
    """æ‰«ææ‰€æœ‰ Live2D æ¨¡å‹"""
    ms = []
    for root, dirs, files in os.walk(MODELS_DIR):
        for file in files:
            if file.endswith(('.model3.json', '.model.json')):
                full_path = os.path.join(root, file)
                # è®¡ç®—ç›¸å¯¹è·¯å¾„
                rel_path = os.path.relpath(full_path, BASE_DIR).replace("\\", "/")
                if not rel_path.startswith("/"): rel_path = "/" + rel_path
                
                folder_name = os.path.basename(os.path.dirname(full_path))
                model_id = folder_name
                
                # é¿å…é‡å¤
                if any(m['id'] == model_id for m in ms): continue
                
                cfg = get_model_config(model_id)
                ms.append({
                    "id": model_id, 
                    "name": model_id, 
                    "path": rel_path, 
                    **cfg
                })
    return sorted(ms, key=lambda x: x['name'])

def scan_backgrounds():
    bgs = []
    for ext in ['*.jpg', '*.jpeg', '*.png', '*.webp', '*.gif']:
        for f in glob.glob(os.path.join(BG_DIR, ext)): 
            bgs.append(os.path.basename(f))
    return sorted(bgs)

def init_model():
    """åˆå§‹åŒ–åŠ è½½ä¸Šæ¬¡ä½¿ç”¨çš„æ¨¡å‹"""
    global CURRENT_MODEL
    ms = scan_models()
    last_id = GLOBAL_STATE.get("current_model_id")
    target = next((m for m in ms if m['id'] == last_id), None)
    
    # å¦‚æœæ‰¾ä¸åˆ°ä¸Šæ¬¡çš„ï¼Œæ‰¾ä¸€ä¸ªåŒ…å« hiyori çš„ï¼Œæˆ–è€…ç¬¬ä¸€ä¸ª
    if not target: target = next((m for m in ms if "hiyori" in m['id'].lower()), None)
    if not target and len(ms) > 0: target = ms[0]
    
    if target: 
        CURRENT_MODEL = target
        GLOBAL_STATE["current_model_id"] = target['id']
        save_state()
        logging.info(f"Initialized model: {target['id']}")

init_model()

# =======================================================================
# TTS æ ¸å¿ƒé€»è¾‘ (çº¯ Python å®ç°ï¼Œç‹¬ç«‹äº‹ä»¶å¾ªç¯)
# =======================================================================
def run_edge_tts_python(text, output_path, voice="zh-CN-XiaoxiaoNeural", rate="+0%", pitch="+0Hz"):
    """
    ä½¿ç”¨ edge-tts åº“ç”ŸæˆéŸ³é¢‘ã€‚
    å…³é”®ç‚¹ï¼šåœ¨çº¿ç¨‹ä¸­åˆ›å»ºå…¨æ–°çš„ asyncio event loopï¼Œé˜²æ­¢ Flask/SocketIO å†²çªã€‚
    """
    logging.info(f"TTS Generating: {text[:15]}... | Voice: {voice}")
    try:
        async def _gen():
            communicate = edge_tts.Communicate(text, voice, rate=rate, pitch=pitch)
            await communicate.save(output_path)
        
        # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
        new_loop = asyncio.new_event_loop()
        asyncio.set_event_loop(new_loop)
        new_loop.run_until_complete(_gen())
        new_loop.close()
        
        if os.path.exists(output_path) and os.path.getsize(output_path) > 0:
            logging.info(f"TTS Success: {output_path}")
            return True
        else:
            logging.error("TTS File created but empty.")
            return False
    except Exception as e:
        logging.error(f"TTS Failed: {e}")
        return False

def bg_tts_task(text, voice, rate, pitch, room=None, sid=None):
    """åå° TTS ä»»åŠ¡"""
    # æ¸…ç†æ ‡ç­¾
    clean_text = re.sub(r'\[(.*?)\]', '', text).strip()
    if not clean_text: return

    fname = f"{uuid.uuid4()}.mp3"
    out_path = os.path.join(AUDIO_DIR, fname)
    
    # é»˜è®¤å‚æ•°å…œåº•
    v = voice if voice else "zh-CN-XiaoxiaoNeural"
    r = rate if rate else "+0%"
    p = pitch if pitch else "+0Hz"

    success = run_edge_tts_python(clean_text, out_path, v, r, p)

    if success:
        url = f"/static/audio/{fname}"
        payload = {'audio': url}
        logging.info(f"Emitting audio event: {url}")
        if room: 
            socketio.emit('audio_response', payload, to=room, namespace='/')
        elif sid: 
            socketio.emit('audio_response', payload, to=sid, namespace='/')
    else:
        logging.error("TTS generation failed completely.")

# ================= è·¯ç”±å®šä¹‰ =================
@app.route('/')
def idx(): 
    return redirect(url_for('pico_v', v=SERVER_VERSION))

@app.route('/pico/<v>')
def pico_v(v):
    r = make_response(render_template('chat.html'))
    # ç¦ç”¨ç¼“å­˜ï¼Œç¡®ä¿å‰ç«¯ä»£ç æ›´æ–°ç«‹å³ç”Ÿæ•ˆ
    r.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
    return r

@app.route('/upload_bg', methods=['POST'])
def upload_bg():
    if 'file' not in request.files: return jsonify({'success': False})
    f = request.files['file']
    if f and '.' in f.filename:
        n = secure_filename(f.filename)
        # æ·»åŠ æ—¶é—´æˆ³é˜²æ­¢é‡å
        final_name = f"{int(time.time())}_{n}"
        f.save(os.path.join(BG_DIR, final_name))
        return jsonify({'success': True})
    return jsonify({'success': False})

@app.route('/update_key', methods=['POST'])
def update_key():
    data = request.json
    new_key = data.get('key', '').strip()
    if not new_key.startswith("AIza"): 
        return jsonify({'success': False, 'msg': 'Key æ ¼å¼ä¸æ­£ç¡® (å¿…é¡»ä»¥ AIza å¼€å¤´)'})
    
    global client, CONFIG
    CONFIG['GEMINI_API_KEY'] = new_key
    
    # å°è¯•é‡æ–°åˆå§‹åŒ–
    try: 
        client = genai.Client(api_key=new_key)
        # ä¿å­˜åˆ°æ–‡ä»¶
        try:
            with open("config.json", "w", encoding='utf-8') as f: 
                json.dump(CONFIG, f, indent=2)
        except: pass
        return jsonify({'success': True})
    except Exception as e:
        return jsonify({'success': False, 'msg': str(e)})

@app.route('/upload_model', methods=['POST'])
def upload_model():
    if 'file' not in request.files: return jsonify({'success': False})
    f = request.files['file']
    if f.filename.endswith('.zip'):
        try:
            n = secure_filename(f.filename).rsplit('.', 1)[0].lower()
            p = os.path.join(MODELS_DIR, n)
            # æ¸…ç†æ—§ç›®å½•
            shutil.rmtree(p, ignore_errors=True)
            
            with zipfile.ZipFile(f, 'r') as z: 
                z.extractall(p)
            
            # æ™ºèƒ½ä¿®æ­£è·¯å¾„ï¼šå¦‚æœè§£å‹åå¤šäº†ä¸€å±‚ç›®å½•
            for root, dirs, files in os.walk(p):
                if any(f.endswith('.model3.json') for f in files):
                    if root != p: 
                         for item in os.listdir(root): 
                             shutil.move(os.path.join(root, item), p)
                    break
            
            return jsonify({'success': True})
        except Exception as e: 
            logging.error(f"Upload model failed: {e}")
            return jsonify({'success': False})
    return jsonify({'success': False})

@app.route('/api/danmaku', methods=['POST'])
def api_danmaku():
    """Bç«™ç›´æ’­å¼¹å¹•å¯¹æ¥æ¥å£"""
    data = request.json
    if not data or 'text' not in data: return jsonify({'success': False})
    user = data.get('username', 'å¼¹å¹•è§‚ä¼—')
    msg = data.get('text', '')
    
    # è®°å½•
    user_msg_obj = {'type': 'chat', 'sender': user, 'text': msg}
    GLOBAL_STATE['chat_history'].append(user_msg_obj)
    save_state()
    
    # å¹¿æ’­
    socketio.emit('chat_message', {'text': msg, 'sender': user}, to='lobby')
    
    # AI å“åº”
    socketio.start_background_task(process_ai_response, user, msg)
    return jsonify({'success': True})

# ================= AI å¤„ç†é€»è¾‘ =================
users = {}
chatroom_chat = None

def init_chatroom():
    global chatroom_chat
    if not client: return
    # ç»„åˆ System Prompt
    sys_prompt = CURRENT_MODEL.get('persona', "") + EMOTION_INSTRUCTION
    try: 
        chatroom_chat = client.chats.create(
            model="gemini-2.5-flash", 
            config={"system_instruction": sys_prompt}
        )
        logging.info("Chatroom initialized.")
    except Exception as e:
        logging.error(f"Chatroom init failed: {e}")

def process_ai_response(sender, msg, img_data=None, sid=None):
    """ç»Ÿä¸€çš„ AI å“åº”å¤„ç†å‡½æ•°"""
    try:
        if not chatroom_chat: init_chatroom()
        if not client: 
            if sid: socketio.emit('system_message', {'text': 'è¯·å…ˆè®¾ç½® API Key'}, to=sid)
            return

        content_parts = []
        if msg: content_parts.append(f"ã€{sender}ã€‘: {msg}")
        
        # å¤„ç†å›¾ç‰‡
        if img_data:
            try:
                if "," in img_data: 
                    header, encoded = img_data.split(",", 1)
                    mime_type = header.split(":")[1].split(";")[0]
                else: 
                    encoded = img_data
                    mime_type = "image/jpeg"
                
                image_bytes = base64.b64decode(encoded)
                content_parts.append(types.Part.from_bytes(data=image_bytes, mime_type=mime_type))
            except Exception as e:
                logging.error(f"Image decode error: {e}")

        if content_parts:
            # è°ƒç”¨ Gemini
            resp = chatroom_chat.send_message(content_parts)
            
            # è§£ææƒ…æ„Ÿæ ‡ç­¾
            emo = 'NORMAL'
            match = re.search(r'\[(HAPPY|ANGRY|SAD|SHOCK|NORMAL)\]', resp.text)
            txt = resp.text
            if match: 
                emo = match.group(1)
                txt = resp.text.replace(match.group(0), '').strip()
            
            # è®°å½• AI å›å¤
            ai_msg_obj = {'type': 'response', 'sender': 'Pico', 'text': txt, 'emotion': emo}
            GLOBAL_STATE['chat_history'].append(ai_msg_obj)
            save_state()
            
            # å¹¿æ’­å›å¤
            socketio.emit('response', {'text': txt, 'sender': 'Pico', 'emotion': emo}, to='lobby')
            
            # è§¦å‘ TTS (å£°éŸ³çš„å…³é”®ï¼)
            bg_tts_task(txt, CURRENT_MODEL['voice'], CURRENT_MODEL['rate'], CURRENT_MODEL['pitch'], room='lobby')
            
    except Exception as e:
        logging.error(f"AI Process Error: {e}")
        if sid: socketio.emit('system_message', {'text': f'AI Error: {e}'}, to=sid)

# ================= Socket.IO äº‹ä»¶ =================
@socketio.on('connect')
def on_connect():
    emit('server_ready', {'status': 'ok'})

@socketio.on('login')
def on_login(d):
    u = d.get('username','').strip() or f"User{str(uuid.uuid4())[:4]}"
    users[request.sid] = {"username": u, "is_admin": False}
    join_room('lobby')
    
    if not chatroom_chat: init_chatroom()
    
    # å‘é€åˆå§‹åŒ–æ•°æ®
    emit('login_success', {
        'username': u, 
        'current_model': CURRENT_MODEL, 
        'current_background': GLOBAL_STATE.get('current_background', '')
    })
    
    # åŒæ­¥å†å²è®°å½•
    emit('history_sync', {'history': GLOBAL_STATE['chat_history']})
    
    # æ¬¢è¿è¯­éŸ³
    socketio.start_background_task(bg_tts_task, f"æ¬¢è¿ {u} è¿›å…¥ç›´æ’­é—´", "zh-CN-XiaoxiaoNeural", "+0%", "+0%", sid=request.sid)

@socketio.on('message')
def on_message(d):
    sid = request.sid
    if sid not in users: return
    
    msg = d.get('text', '')
    img_data = d.get('image', None)
    sender = users[sid]['username']
    
    # ç®¡ç†å‘˜åé—¨
    if "/ç®¡ç†å‘˜" in msg and sender.lower() == "yk": 
        users[sid]['is_admin'] = True
        emit('admin_unlocked')
        return
    
    # è®°å½•ç”¨æˆ·æ¶ˆæ¯
    user_msg_obj = {'type': 'chat', 'sender': sender, 'text': msg}
    if img_data: user_msg_obj['image'] = True 
    GLOBAL_STATE['chat_history'].append(user_msg_obj)
    save_state()
    
    # å¹¿æ’­ç”¨æˆ·æ¶ˆæ¯
    emit('chat_message', {'text': msg, 'sender': sender, 'image': img_data}, to='lobby')
    
    # è§¦å‘ AI
    socketio.start_background_task(process_ai_response, sender, msg, img_data, sid)

def is_admin(sid): 
    return users.get(sid, {}).get('is_admin', False)

@socketio.on('get_studio_data')
def on_get_data():
    emit('studio_data', {
        'models': scan_models(), 
        'current_id': CURRENT_MODEL['id'], 
        'backgrounds': scan_backgrounds(), 
        'current_bg': GLOBAL_STATE.get('current_background', '')
    })

@socketio.on('switch_model')
def on_switch(d):
    global CURRENT_MODEL
    t = next((m for m in scan_models() if m['id'] == d['id']), None)
    if t: 
        CURRENT_MODEL = t
        GLOBAL_STATE["current_model_id"] = t['id']
        save_state()
        init_chatroom()
        emit('model_switched', CURRENT_MODEL, to='lobby')

@socketio.on('switch_background')
def on_switch_bg(d):
    GLOBAL_STATE['current_background'] = d.get('name')
    save_state()
    emit('background_update', {'url': f"/static/backgrounds/{d.get('name')}" if d.get('name') else ""}, to='lobby')

@socketio.on('save_settings')
def on_save(d):
    if not is_admin(request.sid): return
    global CURRENT_MODEL
    try: 
        d['scale'] = float(d['scale'])
        d['x'] = float(d['x'])
        d['y'] = float(d['y'])
    except: pass
    
    updated = save_model_config(d['id'], d)
    if CURRENT_MODEL['id'] == d['id']: 
        CURRENT_MODEL.update(updated)
        init_chatroom()
        emit('model_switched', CURRENT_MODEL, to='lobby')
    emit('toast', {'text': 'âœ… è®¾ç½®å·²ä¿å­˜'})

@socketio.on('delete_model')
def on_del(d):
    if not is_admin(request.sid): return
    if d['id'] != CURRENT_MODEL['id']: 
        shutil.rmtree(os.path.join(MODELS_DIR, d['id']), ignore_errors=True)
        emit('toast',{'text':'ğŸ—‘ï¸ æ¨¡å‹å·²åˆ é™¤'})
        on_get_data()

@socketio.on('download_model')
def on_dl(d):
    if not is_admin(request.sid): return
    name = d.get('name')
    emit('toast', {'text': f'ğŸš€ å¼€å§‹ä¸‹è½½ {name}...', 'type':'info'})
    socketio.start_background_task(bg_dl_task, name)

def bg_dl_task(name):
    # ç®€å•çš„ä¸‹è½½é€»è¾‘ï¼Œè¿™é‡Œä½¿ç”¨ svn export 
    u = f"https://github.com/Live2D/CubismWebSamples/trunk/Samples/Resources/{name}"
    t = os.path.join(MODELS_DIR, name.lower())
    shutil.rmtree(t, ignore_errors=True)
    os.makedirs(t, exist_ok=True)
    try: 
        os.system(f"svn export --force -q {u} {t}")
        socketio.emit('toast', {'text': f'âœ… {name} ä¸‹è½½å®Œæˆ!'}, namespace='/')
    except Exception as e:
        socketio.emit('toast', {'text': f'âŒ ä¸‹è½½å¤±è´¥: {e}', 'type':'error'}, namespace='/')

if __name__ == '__main__':
    logging.info("Starting Pico AI Server...")
    socketio.run(app, host='0.0.0.0', port=5000)
