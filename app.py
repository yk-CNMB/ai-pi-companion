# =======================================================================
# Pico AI Server - ACGN Online TTS ç‰ˆ
# æ ¸å¿ƒé€»è¾‘ï¼šä¼˜å…ˆè°ƒç”¨ ACGN AI åœ¨çº¿ API (GPT-SoVITS)ï¼Œå¤±è´¥åˆ™é™çº§ Edge-TTS
# =======================================================================
import os
import json
import uuid
import time
import re
import threading
import base64
import logging
import asyncio
import edge_tts
import requests 

from flask import Flask, render_template, request, redirect, url_for, jsonify
from flask_socketio import SocketIO, emit, join_room
from google import genai
from google.genai import types
from werkzeug.utils import secure_filename

# æ—¥å¿—é…ç½®
logging.basicConfig(level=logging.INFO, format='[%(asctime)s] %(levelname)s: %(message)s')

app = Flask(__name__, static_folder='static')
app.config['SECRET_KEY'] = 'pico_acgn_key'
app.config['MAX_CONTENT_LENGTH'] = 200 * 1024 * 1024

socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading', ping_timeout=60)
SERVER_VERSION = str(int(time.time()))

# --- ç›®å½•åˆå§‹åŒ– ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
AUDIO_DIR = os.path.join(BASE_DIR, "static", "audio")
MODELS_DIR = os.path.join(BASE_DIR, "static", "live2d")
BG_DIR = os.path.join(BASE_DIR, "static", "backgrounds")
STATE_FILE = os.path.join(BASE_DIR, "server_state.json")
CONFIG_FILE = os.path.join(BASE_DIR, "config.json")

for d in [AUDIO_DIR, MODELS_DIR, BG_DIR]:
    if not os.path.exists(d): os.makedirs(d)

# --- é…ç½®åŠ è½½ ---
CONFIG = {
    "GEMINI_API_KEY": "",
    "DEFAULT_VOICE": "zh-CN-XiaoyiNeural",
    # ACGN AI é…ç½®
    "ACGN_TOKEN": "",          # ç”¨æˆ·æä¾›çš„ Bearer Token
    "ACGN_CHARACTER": "æµè¤",   # é»˜è®¤è§’è‰²ï¼Œå¯ä¿®æ”¹
    "ACGN_API_URL": "https://gsv2p.acgnai.top" 
}

def load_config():
    try:
        if os.path.exists(CONFIG_FILE):
            with open(CONFIG_FILE, "r", encoding='utf-8') as f: 
                lines = [line for line in f.readlines() if not line.strip().startswith("//")]
                if lines: CONFIG.update(json.loads("\n".join(lines)))
    except: pass
load_config()

def save_config():
    try:
        with open(CONFIG_FILE, "w", encoding='utf-8') as f: json.dump(CONFIG, f, indent=2, ensure_ascii=False)
    except: pass

# Gemini åˆå§‹åŒ–
gemini_client = None
chatroom_chat = None

def init_gemini():
    global gemini_client, chatroom_chat
    if CONFIG.get("GEMINI_API_KEY") and "AIza" in CONFIG["GEMINI_API_KEY"]:
        try:
            gemini_client = genai.Client(api_key=CONFIG["GEMINI_API_KEY"])
            chatroom_chat = None 
            logging.info("âœ… Gemini å®¢æˆ·ç«¯å°±ç»ª")
        except Exception as e:
            logging.error(f"Gemini åˆå§‹åŒ–å¤±è´¥: {e}")

init_gemini()

# --- çŠ¶æ€ç®¡ç† ---
GLOBAL_STATE = { "current_model_id": "default", "current_background": "", "chat_history": [] }

def save_state():
    try: with open(STATE_FILE, 'w', encoding='utf-8') as f: json.dump(GLOBAL_STATE, f, ensure_ascii=False)
    except: pass

def load_state():
    global GLOBAL_STATE
    if os.path.exists(STATE_FILE):
        try:
            with open(STATE_FILE, 'r', encoding='utf-8') as f:
                saved = json.load(f)
                if saved: GLOBAL_STATE.update(saved)
                if len(GLOBAL_STATE["chat_history"]) > 100: GLOBAL_STATE["chat_history"] = GLOBAL_STATE["chat_history"][-100:]
        except: pass
load_state()

# æ¨¡å‹ç®¡ç†
CURRENT_MODEL = {"id": "default", "path": "", "persona": "", "voice": "0", "rate": "+0%", "pitch": "+0Hz", "scale": 0.5, "x": 0.5, "y": 0.5}
DEFAULT_INSTRUCTION = "\nã€æŒ‡ä»¤ã€‘å›å¤å¼€å¤´æ ‡è®°å¿ƒæƒ…ï¼š[HAPPY], [ANGRY], [SAD], [SHOCK], [NORMAL]ã€‚"

def get_model_config(mid):
    p = os.path.join(MODELS_DIR, mid, "config.json")
    d = {"persona": f"ä½ æ˜¯{mid}ã€‚{DEFAULT_INSTRUCTION}", "voice": "0", "rate": "+0%", "pitch": "+0Hz", "scale": 0.5, "x": 0.5, "y": 0.5}
    if os.path.exists(p):
        try: with open(p, "r", encoding="utf-8") as f: d.update(json.load(f))
        except: pass
    return d

def save_model_config(mid, data):
    p = os.path.join(MODELS_DIR, mid, "config.json")
    curr = get_model_config(mid)
    curr.update(data)
    try: with open(p, "w", encoding="utf-8") as f: json.dump(curr, f, indent=2, ensure_ascii=False)
    except: pass
    return curr

def scan_models():
    ms = []
    for root, dirs, files in os.walk(MODELS_DIR):
        for file in files:
            if file.endswith(('.model3.json', '.model.json')):
                full_path = os.path.join(root, file)
                rel_path = os.path.relpath(full_path, BASE_DIR).replace("\\", "/")
                if not rel_path.startswith("/"): rel_path = "/" + rel_path
                mid = os.path.basename(os.path.dirname(full_path))
                if any(m['id'] == mid for m in ms): continue
                ms.append({"id": mid, "name": mid, "path": rel_path, **get_model_config(mid)})
    return sorted(ms, key=lambda x: x['name'])

def init_model():
    global CURRENT_MODEL
    ms = scan_models()
    target = next((m for m in ms if m['id'] == GLOBAL_STATE.get("current_model_id")), ms[0] if ms else None)
    if target: 
        CURRENT_MODEL = target
        GLOBAL_STATE["current_model_id"] = target['id']
        save_state()
init_model()

# ================= è¯­éŸ³åˆæˆæ ¸å¿ƒ (ACGN + Edge) =================

def cleanup_audio_dir():
    try:
        now = time.time()
        for f in os.listdir(AUDIO_DIR):
            if os.path.getmtime(os.path.join(AUDIO_DIR, f)) < now - 300: os.remove(os.path.join(AUDIO_DIR, f))
    except: pass

def generate_acgn_tts(text):
    """è°ƒç”¨ ACGN AI åœ¨çº¿ API"""
    token = CONFIG.get("ACGN_TOKEN")
    char_name = CONFIG.get("ACGN_CHARACTER", "æµè¤") # é»˜è®¤æµè¤
    
    if not token: 
        logging.warning("âš ï¸ ACGN Token æœªé…ç½®ï¼Œè·³è¿‡åœ¨çº¿åˆæˆ")
        return None
    
    try:
        logging.info(f"ğŸ“¡ è¯·æ±‚ ACGN è¯­éŸ³ ({char_name}): {text[:10]}...")
        
        # æ„é€ è¯·æ±‚ (åŸºäºé€šå¸¸ GSV2P æ¥å£çŒœæµ‹ï¼Œéœ€è¦å…·ä½“æ–‡æ¡£æ ¡å‡†)
        # è¿™é‡Œå‡è®¾å®ƒæ˜¯ä¸€ä¸ªå…¼å®¹ GPT-SoVITS åè®®çš„ API
        # å¾ˆå¤šç¬¬ä¸‰æ–¹ GSV æ¥å£ä½¿ç”¨ GET /?text=...&text_language=zh&character=...
        
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬å°è¯•æœ€é€šç”¨çš„ params ç»“æ„
        url = CONFIG.get("ACGN_API_URL")
        # å¦‚æœ URL ç»“å°¾æ²¡æœ‰ /ï¼Œè¡¥ä¸Š
        if not url.endswith("/"): url += "/"
        
        # å°è¯• endpoint: /tts æˆ– ç›´æ¥æ ¹è·¯å¾„ (å–å†³äºæœåŠ¡å•†å®ç°)
        # æ—¢ç„¶æ˜¯ gsv2p.acgnai.topï¼Œå¤§æ¦‚ç‡æ˜¯å…¼å®¹ GPT-SoVITS å®˜æ–¹ API æ ¼å¼
        # å°è¯•è°ƒç”¨ / (æ ¹è·¯å¾„) æˆ–è€… /tts
        
        headers = {
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/json"  # æœ‰äº›æ¥å£éœ€è¦
        }
        
        # å°è¯•æ–¹æ¡ˆ A: GET è¯·æ±‚ (æœ€å¸¸è§)
        # å‚æ•°åé€šå¸¸æ˜¯: text, text_language, refer_wav_path (æˆ–è€… character/emotion)
        # ç”±äºæ˜¯å…¬å…±åº“ï¼Œå¯èƒ½æœ‰ä¸€ä¸ª 'character' å‚æ•°æˆ–è€… 'speaker'
        params = {
            "text": text,
            "text_language": "zh",
            "character": char_name, # å…³é”®å‚æ•°ï¼šè§’è‰²å
            "format": "wav"
        }
        
        # å‘èµ·è¯·æ±‚ (è¿™é‡Œå‡è®¾æ˜¯ GET æ ¹è·¯å¾„ï¼Œå¦‚æœä¸è¡Œè¯·å°è¯• /tts)
        resp = requests.get(url, headers=headers, params=params, timeout=10)
        
        if resp.status_code == 200:
            # æ£€æŸ¥è¿”å›æ˜¯ä¸æ˜¯éŸ³é¢‘ (content-type)
            if "audio" in resp.headers.get("Content-Type", "") or len(resp.content) > 1000:
                filename = f"acgn_{uuid.uuid4().hex}.wav"
                filepath = os.path.join(AUDIO_DIR, filename)
                with open(filepath, 'wb') as f: f.write(resp.content)
                logging.info("âœ… ACGN è¯­éŸ³ç”ŸæˆæˆåŠŸ")
                return f"/static/audio/{filename}"
            else:
                logging.warning(f"âš ï¸ ACGN è¿”å›ééŸ³é¢‘æ•°æ®: {resp.text[:50]}")
        else:
            logging.warning(f"âš ï¸ ACGN è¯·æ±‚å¤±è´¥: {resp.status_code} - {resp.text[:50]}")
            
    except Exception as e:
        logging.warning(f"âš ï¸ ACGN API å¼‚å¸¸ ({e})ï¼Œå°†é™çº§åˆ° Edge-TTS")
        
    return None

def run_edge_tts_sync(text, voice, output_file, rate="+0%", pitch="+0Hz"):
    async def _amain():
        communicate = edge_tts.Communicate(text, voice, rate=rate, pitch=pitch)
        await communicate.save(output_file)
    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(_amain())
        loop.close()
        return True
    except: return False

def generate_audio_smart(text, voice_id, rate, pitch):
    cleanup_audio_dir()
    clean_text = re.sub(r'\[.*?\]', '', text).strip()
    if not clean_text: return None

    # 1. ä¼˜å…ˆå°è¯• ACGN åœ¨çº¿è¯­éŸ³ (å½“ voice_id é€‰äº† 'acgn' æˆ–é…ç½®äº† Token ä¸” voice_id ä¸ºé»˜è®¤)
    if voice_id == "acgn" or (CONFIG.get("ACGN_TOKEN") and voice_id == "0"):
        url = generate_acgn_tts(clean_text)
        if url: return url

    # 2. Edge-TTS å…œåº•
    filename = f"edge_{uuid.uuid4().hex}.mp3"
    filepath = os.path.join(AUDIO_DIR, filename)
    
    voice_map = {"0": "zh-CN-XiaoyiNeural", "1": "zh-CN-XiaoxiaoNeural", "2": "zh-CN-YunxiNeural", "acgn": "zh-CN-XiaoyiNeural"}
    target_voice = voice_map.get(str(voice_id), "zh-CN-XiaoyiNeural")
    if "Neural" in str(voice_id): target_voice = voice_id

    logging.info(f"ğŸ™ï¸ Edge-TTS è¯·æ±‚: {clean_text[:10]}...")
    if run_edge_tts_sync(clean_text, target_voice, filepath, rate, pitch):
        return f"/static/audio/{filename}"
    return None

def bg_tts_task(text, voice, rate, pitch, room=None, sid=None):
    audio_url = generate_audio_smart(text, voice, rate, pitch)
    if audio_url:
        payload = {'audio': audio_url}
        if room: socketio.emit('audio_response', payload, to=room, namespace='/')
        elif sid: socketio.emit('audio_response', payload, to=sid, namespace='/')

# ================= Flask è·¯ç”± =================
@app.route('/')
def idx(): return redirect(url_for('pico_v', v=SERVER_VERSION))

@app.route('/pico/<v>')
def pico_v(v):
    r = make_response(render_template('chat.html'))
    r.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
    return r

@app.route('/update_key', methods=['POST'])
def update_key():
    data = request.json
    new_key = data.get('key', '').strip()
    if data.get('type') == 'gemini':
        if not new_key.startswith("AIza"): return jsonify({'success': False, 'msg': 'Key æ ¼å¼é”™è¯¯'})
        global gemini_client, chatroom_chat
        CONFIG['GEMINI_API_KEY'] = new_key
        save_config()
        init_gemini()
        return jsonify({'success': True})
    return jsonify({'success': False})

@app.route('/upload_bg', methods=['POST'])
def upload_bg():
    f = request.files.get('file')
    if f: f.save(os.path.join(BG_DIR, f"{int(time.time())}_{secure_filename(f.filename)}")); return jsonify({'success': True})
    return jsonify({'success': False})

@app.route('/upload_model', methods=['POST'])
def upload_model():
    f = request.files.get('file')
    if f and f.filename.endswith('.zip'):
        try:
            n = secure_filename(f.filename).rsplit('.', 1)[0].lower()
            p = os.path.join(MODELS_DIR, n)
            shutil.rmtree(p, ignore_errors=True)
            with zipfile.ZipFile(f, 'r') as z: z.extractall(p)
            for root, _, files in os.walk(p):
                if any(fn.endswith('.model3.json') for fn in files):
                    if root != p: 
                        for item in os.listdir(root): shutil.move(os.path.join(root, item), p)
                    break
            return jsonify({'success': True})
        except: pass
    return jsonify({'success': False})

@app.route('/api/danmaku', methods=['POST'])
def api_danmaku():
    data = request.json
    if not data or 'text' not in data: return jsonify({'success': False})
    user = data.get('username', 'Bç«™å¼¹å¹•')
    msg = data.get('text', '')
    GLOBAL_STATE['chat_history'].append({'type':'chat', 'sender': user, 'text': msg})
    save_state()
    socketio.emit('chat_message', {'text': msg, 'sender': user}, to='lobby')
    socketio.start_background_task(process_ai_response, user, msg)
    return jsonify({'success': True})

# ================= Socket é€»è¾‘ =================
def init_chatroom():
    global chatroom_chat
    if not gemini_client: return
    sys_prompt = CURRENT_MODEL.get('persona', DEFAULT_INSTRUCTION)
    try: chatroom_chat = gemini_client.chats.create(model="gemini-2.5-flash", config={"system_instruction": sys_prompt})
    except: pass

def process_ai_response(sender, msg, img_data=None, sid=None):
    global chatroom_chat
    try:
        if not chatroom_chat: init_chatroom()
        if not gemini_client:
            if sid: socketio.emit('system_message', {'text': 'è¯·è®¾ç½® Gemini Key'}, to=sid)
            return
        
        content = []
        if msg: content.append(f"ã€{sender}ã€‘: {msg}")
        if img_data:
            try:
                b64 = img_data.split(",", 1)[1] if "," in img_data else img_data
                content.append(types.Part.from_bytes(data=base64.b64decode(b64), mime_type="image/jpeg"))
            except: pass
            
        try:
            resp = chatroom_chat.send_message(content)
            txt = resp.text
        except Exception as e:
            if "closed" in str(e).lower(): init_chatroom(); return # ç®€å•é‡è¯•
            txt = f"(ç³»ç»Ÿ: {str(e)[:50]})"

        emo='NORMAL'
        match=re.search(r'\[(HAPPY|ANGRY|SAD|SHOCK|NORMAL)\]', txt)
        if match: 
            emo=match.group(1)
            txt=txt.replace(match.group(0),'').strip()
            
        GLOBAL_STATE['chat_history'].append({'type': 'response', 'sender': 'Pico', 'text': txt, 'emotion': emo})
        save_state()
        socketio.emit('response', {'text': txt, 'sender': 'Pico', 'emotion': emo}, to='lobby')
        socketio.start_background_task(bg_tts_task, txt, CURRENT_MODEL['voice'], CURRENT_MODEL['rate'], CURRENT_MODEL['pitch'], room='lobby')
        
    except Exception as e: logging.error(f"AI Error: {e}")

@socketio.on('connect')
def on_connect(): emit('server_ready', {'status': 'ok'})

@socketio.on('login')
def on_login(d):
    u = d.get('username', 'User')
    join_room('lobby')
    if not chatroom_chat: init_chatroom()
    emit('login_success', {'username': u, 'current_model': CURRENT_MODEL, 'current_background': GLOBAL_STATE.get('current_background', '')})
    emit('history_sync', {'history': GLOBAL_STATE['chat_history']})
    socketio.start_background_task(bg_tts_task, f"æ¬¢è¿ {u}", CURRENT_MODEL['voice'], "+0%", "+0%", sid=request.sid)

@socketio.on('message')
def on_msg(d):
    msg = d.get('text', '')
    
    # â˜…â˜…â˜… æ–°å¢ï¼šACGN é…ç½®æŒ‡ä»¤ â˜…â˜…â˜…
    if msg.startswith("/acgn_token "):
        t = msg.replace("/acgn_token ", "").strip()
        CONFIG["ACGN_TOKEN"] = t
        save_config()
        emit('system_message', {'text': 'âœ… ACGN Token å·²ä¿å­˜'})
        return
    if msg.startswith("/acgn_char "):
        c = msg.replace("/acgn_char ", "").strip()
        CONFIG["ACGN_CHARACTER"] = c
        save_config()
        emit('system_message', {'text': f'âœ… ACGN è§’è‰²å·²è®¾ä¸º: {c}'})
        return

    sender = "User"
    GLOBAL_STATE['chat_history'].append({'type':'chat', 'sender':sender, 'text':msg, 'image': bool(d.get('image'))})
    save_state()
    emit('chat_message', {'text':msg, 'sender':sender, 'image':d.get('image')}, to='lobby')
    socketio.start_background_task(process_ai_response, sender, msg, d.get('image'), request.sid)

@socketio.on('get_studio_data')
def on_get_data():
    # å¢åŠ  ACGN é€‰é¡¹
    voices = [
        {"id":"0", "name":"ğŸ§ é»˜è®¤: æ™“ä¼Š (å¾®è½¯)"},
        {"id":"1", "name":"ğŸ§ é»˜è®¤: æ™“æ™“ (å¾®è½¯)"},
        {"id":"acgn", "name":"âœ¨ ACGN åœ¨çº¿ (éœ€é…ç½®)"}
    ]
    emit('studio_data', {
        'models': scan_models(), 'current_id': CURRENT_MODEL['id'], 
        'voices': voices, 'backgrounds': scan_backgrounds(), 
        'current_bg': GLOBAL_STATE.get('current_background', ''),
        'gemini_key_status': 'OK' if gemini_client else 'MISSING',
    })

@socketio.on('switch_model')
def on_sw(d):
    global CURRENT_MODEL
    t = next((m for m in scan_models() if m['id'] == d['id']), None)
    if t: 
        CURRENT_MODEL = t; GLOBAL_STATE["current_model_id"] = t['id']; save_state(); init_chatroom()
        emit('model_switched', CURRENT_MODEL, to='lobby')

@socketio.on('save_settings')
def on_sav(d):
    global CURRENT_MODEL
    updated = save_model_config(d['id'], d)
    if CURRENT_MODEL['id'] == d['id']: CURRENT_MODEL.update(updated); init_chatroom()
    emit('toast', {'text': 'âœ… ä¿å­˜æˆåŠŸ'})

@socketio.on('switch_background')
def on_sw_bg(d):
    GLOBAL_STATE['current_background'] = d.get('name'); save_state()
    emit('background_update', {'url': f"/static/backgrounds/{d.get('name')}" if d.get('name') else ""}, to='lobby')

if __name__ == '__main__':
    logging.info("Starting Pico AI (ACGN Mode)...")
    socketio.run(app, host='0.0.0.0', port=5000)
