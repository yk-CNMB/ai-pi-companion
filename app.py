# =======================================================================
# Pico AI Server - ULTIMATE SAFEGUARD EDITION
# åŒ…å«ï¼šGemini 429 é”™è¯¯è‡ªåŠ¨å¤„ç†ã€TTS å‚æ•°æ™ºèƒ½æ¸…æ´—ã€å®Œæ•´å‰ç«¯å›é€€æœºåˆ¶
# è§£å†³ï¼šNoAudioReceived é”™è¯¯ (é€šè¿‡å¼ºåˆ¶ä¼ é€’åˆè§„å‚æ•°)
# =======================================================================
import os
import json
import uuid
import time
import glob
import shutil
import re
import zipfile
import threading
import requests
import urllib.parse
import base64
import asyncio
import logging
import subprocess
import sys
import traceback

# å°è¯•å¯¼å…¥ edge_tts
try:
    import edge_tts
    print("âœ… Python å†…éƒ¨åº“ edge_tts å·²åŠ è½½")
except ImportError:
    print("âš ï¸ Python å†…éƒ¨åº“ edge_tts æœªæ‰¾åˆ°ï¼Œå°†å®Œå…¨ä¾èµ–å‘½ä»¤è¡Œæ¨¡å¼")

from flask import Flask, render_template, request, make_response, redirect, url_for, jsonify
from flask_socketio import SocketIO, emit, join_room, leave_room
from google import genai
from google.genai import types
from werkzeug.utils import secure_filename

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO, 
    format='[%(asctime)s] %(levelname)s: %(message)s'
)

app = Flask(__name__, static_folder='static')
app.config['SECRET_KEY'] = 'pico_safeguard_key'
app.config['MAX_CONTENT_LENGTH'] = 200 * 1024 * 1024

# SocketIO é…ç½®
socketio = SocketIO(app, 
    cors_allowed_origins="*", 
    async_mode='threading', 
    ping_timeout=60, 
    ping_interval=25,
    max_http_buffer_size=100*1024*1024
)

SERVER_VERSION = str(int(time.time()))

# --- ç›®å½•åˆå§‹åŒ– ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
AUDIO_DIR = os.path.join(BASE_DIR, "static", "audio")
MODELS_DIR = os.path.join(BASE_DIR, "static", "live2d")
BG_DIR = os.path.join(BASE_DIR, "static", "backgrounds")
STATE_FILE = os.path.join(BASE_DIR, "server_state.json")
CONFIG_FILE = os.path.join(BASE_DIR, "config.json")

for d in [AUDIO_DIR, MODELS_DIR, BG_DIR]:
    if not os.path.exists(d):
        try:
            os.makedirs(d)
            logging.info(f"åˆ›å»ºç›®å½•: {d}")
        except Exception as e:
            logging.error(f"åˆ›å»ºç›®å½•å¤±è´¥ {d}: {e}")

# --- é…ç½®åŠ è½½ ---
CONFIG = {
    "GEMINI_API_KEY": "",
    "TTS_VOICE": "zh-CN-XiaoxiaoNeural",
    "TTS_PROXY": ""  # å¯é€‰ï¼šHTTPä»£ç†åœ°å€
}

try:
    if os.path.exists(CONFIG_FILE):
        with open(CONFIG_FILE, "r", encoding='utf-8') as f: 
            lines = [line for line in f.readlines() if not line.strip().startswith("//")]
            if lines: CONFIG.update(json.loads("\n".join(lines)))
except Exception as e:
    logging.error(f"åŠ è½½é…ç½®æ–‡ä»¶å‡ºé”™: {e}")

# Gemini åˆå§‹åŒ–
client = None
api_key = CONFIG.get("GEMINI_API_KEY")
if api_key and "AIza" in api_key:
    try:
        client = genai.Client(api_key=api_key)
        logging.info("Gemini å®¢æˆ·ç«¯å°±ç»ª")
    except Exception as e:
        logging.error(f"Gemini åˆå§‹åŒ–å¤±è´¥: {e}")

# --- çŠ¶æ€ç®¡ç† ---
GLOBAL_STATE = { 
    "current_model_id": "default", 
    "current_background": "", 
    "chat_history": [] 
}

def save_state():
    try:
        with open(STATE_FILE, 'w', encoding='utf-8') as f:
            json.dump(GLOBAL_STATE, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logging.error(f"ä¿å­˜çŠ¶æ€å¤±è´¥: {e}")

def load_state():
    global GLOBAL_STATE
    if os.path.exists(STATE_FILE):
        try:
            with open(STATE_FILE, 'r', encoding='utf-8') as f:
                saved = json.load(f)
                if saved: GLOBAL_STATE.update(saved)
                if len(GLOBAL_STATE["chat_history"]) > 100:
                    GLOBAL_STATE["chat_history"] = GLOBAL_STATE["chat_history"][-100:]
        except: pass

load_state()

# å½“å‰æ¨¡å‹ç¼“å­˜
CURRENT_MODEL = {
    "id": "default", "path": "", "persona": "", "voice": "zh-CN-XiaoxiaoNeural", 
    "rate": "+0%", "pitch": "+0Hz", "scale": 0.5, "x": 0.5, "y": 0.5
}
DEFAULT_INSTRUCTION = "\nã€æŒ‡ä»¤ã€‘å›å¤å¼€å¤´æ ‡è®°å¿ƒæƒ…ï¼š[HAPPY], [ANGRY], [SAD], [SHOCK], [NORMAL]ã€‚"

def get_model_config(mid):
    p = os.path.join(MODELS_DIR, mid, "config.json")
    d = {
        "persona": f"ä½ æ˜¯{mid}ã€‚{DEFAULT_INSTRUCTION}", 
        "voice": "zh-CN-XiaoxiaoNeural", 
        "rate": "+0%", "pitch": "+0Hz", 
        "scale": 0.5, "x": 0.5, "y": 0.5
    }
    if os.path.exists(p):
        try:
            with open(p, "r", encoding="utf-8") as f: 
                loaded = json.load(f)
                if loaded.get('persona'): d['persona'] = loaded['persona']
                d.update(loaded)
        except: pass
    return d

def save_model_config(mid, data):
    p = os.path.join(MODELS_DIR, mid, "config.json")
    curr = get_model_config(mid)
    curr.update(data)
    try:
        with open(p, "w", encoding="utf-8") as f:
            json.dump(curr, f, indent=2, ensure_ascii=False)
    except: pass
    return curr

def scan_models():
    ms = []
    for root, dirs, files in os.walk(MODELS_DIR):
        for file in files:
            if file.endswith(('.model3.json', '.model.json')):
                full_path = os.path.join(root, file)
                rel_path = os.path.relpath(full_path, BASE_DIR).replace("\\", "/")
                if not rel_path.startswith("/"): rel_path = "/" + rel_path
                model_id = os.path.basename(os.path.dirname(full_path))
                if any(m['id'] == model_id for m in ms): continue
                cfg = get_model_config(model_id)
                ms.append({"id": model_id, "name": model_id, "path": rel_path, **cfg})
    return sorted(ms, key=lambda x: x['name'])

def scan_backgrounds():
    bgs = []
    for ext in ['*.jpg', '*.jpeg', '*.png', '*.webp', '*.gif']:
        for f in glob.glob(os.path.join(BG_DIR, ext)): bgs.append(os.path.basename(f))
    return sorted(bgs)

def init_model():
    global CURRENT_MODEL
    ms = scan_models()
    last_id = GLOBAL_STATE.get("current_model_id")
    target = next((m for m in ms if m['id'] == last_id), None)
    if not target and len(ms) > 0: target = ms[0]
    if target: 
        CURRENT_MODEL = target
        GLOBAL_STATE["current_model_id"] = target['id']
        save_state()

init_model()

# ================= TTS æ ¸å¿ƒ (å¸¦å‚æ•°æ¸…æ´— V2) =================

def clean_tts_param(val, unit):
    """
    å¼ºåˆ¶æ¸…æ´— TTS å‚æ•°ï¼Œç¡®ä¿æ ¼å¼ä¸º [+-]xxUNITã€‚
    """
    s = str(val).strip()
    
    # æå–æ•°å­—å’Œç¬¦å·
    # ç¤ºä¾‹: "+0%" -> "+0"
    nums = re.sub(r'[^\d\+\-]', '', s)
    
    if not nums or nums in ['+', '-']:
        n = 0
    else:
        try:
            n = int(nums)
        except ValueError:
            n = 0
            
    # å¼ºåˆ¶æ ¼å¼åŒ–ï¼šå¸¦ç¬¦å·æ•´æ•° + å•ä½
    return f"{n:+}{unit}"


def run_edge_tts_cmd(text, output_path, voice, rate, pitch):
    """
    æ‰§è¡Œ TTS å‘½ä»¤ã€‚ä½¿ç”¨æ¸…æ´—åçš„å‚æ•°ã€‚
    """
    try:
        # â˜…â˜…â˜… å…³é”®ä¿®å¤ï¼šæ¸…æ´—å‚æ•°ï¼Œç¡®ä¿æ ¼å¼æ­£ç¡® â˜…â˜…â˜…
        # å³ä½¿å€¼æ˜¯ +0%ï¼Œæ¸…æ´—åä¹Ÿä¼šæ˜¯ +0% æˆ– +0Hz
        safe_rate = clean_tts_param(rate, "%")
        safe_pitch = clean_tts_param(pitch, "Hz")
        
        logging.info(f"TTS æœ€ç»ˆå‚æ•°: Rate={safe_rate}, Pitch={safe_pitch}")

        cmd = [
            sys.executable, "-m", "edge_tts",
            "--text", text,
            "--write-media", output_path,
            "--voice", voice,
            "--rate", safe_rate,
            "--pitch", safe_pitch # å§‹ç»ˆä¼ é€’ï¼Œç¡®ä¿å…¼å®¹æ€§
        ]
        
        # æ³¨å…¥ä»£ç†é…ç½®
        my_env = os.environ.copy()
        proxy_url = CONFIG.get("TTS_PROXY", "").strip()
        if proxy_url:
            my_env["http_proxy"] = proxy_url
            my_env["https_proxy"] = proxy_url
        
        logging.info(f"æ‰§è¡Œ TTS å‘½ä»¤: {' '.join(cmd)}")
        
        result = subprocess.run(
            cmd, 
            check=True, 
            stdout=subprocess.PIPE, 
            stderr=subprocess.PIPE,
            timeout=60,
            env=my_env
        )
        
        # æ£€æŸ¥æ˜¯å¦æ”¶åˆ°éŸ³é¢‘ (å¦‚æœ stderr æœ‰å†…å®¹ï¼Œè¡¨ç¤ºå¯èƒ½æœ‰éè‡´å‘½é”™è¯¯ï¼Œä½†æˆ‘ä»¬ä¸»è¦çœ‹ NoAudioReceived)
        if b"No audio was received" in result.stderr:
            return False, result.stderr.decode('utf-8', errors='ignore')
            
        return True, ""
    except Exception as e:
        err_msg = str(e)
        if hasattr(e, 'stderr') and e.stderr: 
            err_msg = e.stderr.decode('utf-8', errors='ignore')
        logging.error(f"TTS å¤±è´¥: {err_msg}")
        return False, err_msg

def bg_tts_task(text, voice, rate, pitch, room=None, sid=None):
    """åå°ä»»åŠ¡ï¼šç”Ÿæˆå¹¶æ¨é€ï¼Œæˆ–è€…è§¦å‘å‰ç«¯é™çº§"""
    clean_text = re.sub(r'\[(.*?)\]', '', text).strip()
    if not clean_text: return

    fname = f"{uuid.uuid4()}.mp3"
    out_path = os.path.join(AUDIO_DIR, fname)
    
    # å°è¯•æœåŠ¡å™¨ç”Ÿæˆ
    success, err_reason = run_edge_tts_cmd(clean_text, out_path, voice, rate, pitch)

    if success and os.path.exists(out_path) and os.path.getsize(out_path) > 0:
        url = f"/static/audio/{fname}"
        payload = {'audio': url}
        logging.info(f"âœ… è¯­éŸ³ç”ŸæˆæˆåŠŸ: {url}")
        
        if room: socketio.emit('audio_response', payload, to=room, namespace='/')
        elif sid: socketio.emit('audio_response', payload, to=sid, namespace='/')
    else:
        # ç”Ÿæˆå¤±è´¥ï¼ŒæŠŠæ–‡æœ¬å‘ç»™å‰ç«¯ï¼Œè®©æµè§ˆå™¨è¯»
        logging.error(f"âŒ è¯­éŸ³ç”Ÿæˆå¤±è´¥ï¼Œåˆ‡æ¢å‰ç«¯åˆæˆ: {err_reason}")
        err_payload = {
            'msg': f'TTSç½‘ç»œè¶…æ—¶ï¼Œåˆ‡æ¢æœ¬åœ°è¯­éŸ³', 
            'text': clean_text,
            'type': 'warning' # å‹å¥½æç¤º
        }
        if room: socketio.emit('audio_failed', err_payload, to=room, namespace='/')
        elif sid: socketio.emit('audio_failed', err_payload, to=sid, namespace='/')

# ================= Flask è·¯ç”± =================
@app.route('/')
def idx(): return redirect(url_for('pico_v', v=SERVER_VERSION))

@app.route('/pico/<v>')
def pico_v(v):
    r = make_response(render_template('chat.html'))
    r.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
    return r

@app.route('/update_key', methods=['POST'])
def update_key():
    data = request.json
    new_key = data.get('key', '').strip()
    if not new_key.startswith("AIza"): return jsonify({'success': False, 'msg': 'Keyæ ¼å¼é”™è¯¯'})
    global client, CONFIG; CONFIG['GEMINI_API_KEY'] = new_key
    try: 
        client = genai.Client(api_key=new_key)
        with open(CONFIG_FILE, "w", encoding='utf-8') as f: json.dump(CONFIG, f, indent=2)
        return jsonify({'success': True})
    except Exception as e: return jsonify({'success': False, 'msg': str(e)})

@app.route('/upload_bg', methods=['POST'])
def upload_bg():
    if 'file' not in request.files: return jsonify({'success': False})
    f = request.files['file']
    if f and '.' in f.filename:
        n = secure_filename(f.filename)
        f.save(os.path.join(BG_DIR, f"{int(time.time())}_{n}"))
        return jsonify({'success': True})
    return jsonify({'success': False})

@app.route('/upload_model', methods=['POST'])
def upload_model():
    if 'file' not in request.files: return jsonify({'success': False})
    f = request.files['file']
    if f.filename.endswith('.zip'):
        try:
            n = secure_filename(f.filename).rsplit('.', 1)[0].lower()
            p = os.path.join(MODELS_DIR, n)
            shutil.rmtree(p, ignore_errors=True)
            with zipfile.ZipFile(f, 'r') as z: z.extractall(p)
            for root, dirs, files in os.walk(p):
                if any(f.endswith('.model3.json') for f in files):
                    if root != p: 
                         for item in os.listdir(root): shutil.move(os.path.join(root, item), p)
                    break
            return jsonify({'success': True})
        except: return jsonify({'success': False})
    return jsonify({'success': False})

@app.route('/api/danmaku', methods=['POST'])
def api_danmaku():
    data = request.json
    if not data or 'text' not in data: return jsonify({'success': False})
    user = data.get('username', 'Bç«™å¼¹å¹•')
    msg = data.get('text', '')
    user_msg_obj = {'type': 'chat', 'sender': user, 'text': msg}
    GLOBAL_STATE['chat_history'].append(user_msg_obj)
    save_state()
    socketio.emit('chat_message', {'text': msg, 'sender': user}, to='lobby')
    socketio.start_background_task(process_ai_response, user, msg)
    return jsonify({'success': True})

# ================= AI é€»è¾‘ (å¸¦ 429 ä¿æŠ¤) =================
users = {}
chatroom_chat = None

def init_chatroom():
    global chatroom_chat
    if not client: return
    sys_prompt = CURRENT_MODEL.get('persona', "")
    if not sys_prompt: sys_prompt = DEFAULT_INSTRUCTION
    try: chatroom_chat = client.chats.create(model="gemini-2.5-flash", config={"system_instruction": sys_prompt})
    except: pass

def process_ai_response(sender, msg, img_data=None, sid=None):
    try:
        if not chatroom_chat: init_chatroom()
        
        if not client: 
            if sid: socketio.emit('system_message', {'text': 'è¯·è®¾ç½® API Key'}, to=sid)
            return
        
        content = []
        if msg: content.append(f"ã€{sender}ã€‘: {msg}")
        if img_data:
            try:
                if "," in img_data: _, encoded = img_data.split(",", 1)
                else: encoded = img_data
                content.append(types.Part.from_bytes(data=base64.b64decode(encoded), mime_type="image/jpeg"))
            except: pass
            
        # â˜…â˜…â˜… 429 é”™è¯¯ä¿æŠ¤ â˜…â˜…â˜…
        try:
            resp = chatroom_chat.send_message(content)
            txt = resp.text
        except Exception as e:
            err_str = str(e)
            if "429" in err_str or "RESOURCE_EXHAUSTED" in err_str:
                logging.error("AI 429 é™æµä¿æŠ¤è§¦å‘")
                txt = "ï¼ˆç³»ç»Ÿï¼šAPI è°ƒç”¨æ¬¡æ•°å·²è€—å°½ï¼Œè¯·ç¨åæˆ–æ›´æ¢ Key å†è¯•ï¼‰"
            else:
                raise e # å…¶ä»–é”™è¯¯ç»§ç»­æŠ›å‡º

        emo='NORMAL'
        match=re.search(r'\[(HAPPY|ANGRY|SAD|SHOCK|NORMAL)\]', txt)
        if match: 
            emo=match.group(1)
            txt=txt.replace(match.group(0),'').strip()
            
        ai_msg = {'type': 'response', 'sender': 'Pico', 'text': txt, 'emotion': emo}
        GLOBAL_STATE['chat_history'].append(ai_msg)
        save_state()
        
        socketio.emit('response', {'text': txt, 'sender': 'Pico', 'emotion': emo}, to='lobby')
        bg_tts_task(txt, CURRENT_MODEL['voice'], CURRENT_MODEL['rate'], CURRENT_MODEL['pitch'], room='lobby')
        
    except Exception as e:
        logging.error(f"AI Error: {e}")
        err_msg = str(e)
        if sid: socketio.emit('system_message', {'text': f'AI Error: {err_msg[:50]}...'}, to=sid)

# ================= Socket Events =================
@socketio.on('connect')
def on_connect(): emit('server_ready', {'status': 'ok'})

@socketio.on('login')
def on_login(d):
    u = d.get('username', '').strip() or "User"
    users[request.sid] = {"username": u, "is_admin": False}
    join_room('lobby')
    if not chatroom_chat: init_chatroom()
    emit('login_success', {'username': u, 'current_model': CURRENT_MODEL, 'current_background': GLOBAL_STATE.get('current_background', '')})
    emit('history_sync', {'history': GLOBAL_STATE['chat_history']})
    socketio.start_background_task(bg_tts_task, f"æ¬¢è¿ {u}", CURRENT_MODEL['voice'], "+0%", "+0%", sid=request.sid)

@socketio.on('message')
def on_msg(d):
    sid = request.sid
    if sid not in users: return
    msg = d.get('text', '')
    img = d.get('image', None)
    sender = users[sid]['username']
    
    if "/ç®¡ç†å‘˜" in msg and sender.lower() == "yk":
        users[sid]['is_admin'] = True
        emit('admin_unlocked')
        return

    GLOBAL_STATE['chat_history'].append({'type':'chat', 'sender':sender, 'text':msg, 'image': bool(img)})
    save_state()
    emit('chat_message', {'text':msg, 'sender':sender, 'image':img}, to='lobby')
    socketio.start_background_task(process_ai_response, sender, msg, img, sid)

def is_admin(sid): return users.get(sid, {}).get('is_admin', False)

@socketio.on('get_studio_data')
def on_get_data():
    voices = [
        {"id":"zh-CN-XiaoxiaoNeural", "name":"ğŸ‡¨ğŸ‡³ æ™“æ™“ (å¥³å£°)"},
        {"id":"zh-CN-YunxiNeural", "name":"ğŸ‡¨ğŸ‡³ äº‘å¸Œ (å°‘å¹´)"},
        {"id":"zh-CN-YunjianNeural", "name":"ğŸ‡¨ğŸ‡³ äº‘å¥ (æ–°é—»)"},
        {"id":"zh-CN-XiaoyiNeural", "name":"ğŸ‡¨ğŸ‡³ æ™“ä¼Š (å¯çˆ±)"},
        {"id":"zh-TW-HsiaoChenNeural", "name":"ğŸ‡¹ğŸ‡¼ æ™“è‡» (å°æ¹¾)"},
        {"id":"zh-HK-HiuMaanNeural", "name":"ğŸ‡­ğŸ‡° æ™“æ›¼ (ç²¤è¯­)"},
        {"id":"en-US-AnaNeural", "name":"ğŸ‡ºğŸ‡¸ Ana (è‹±æ–‡)"},
        {"id":"en-US-GuyNeural", "name":"ğŸ‡ºğŸ‡¸ Guy (è‹±æ–‡ç”·)"},
        {"id":"ja-JP-NanamiNeural", "name":"ğŸ‡¯ğŸ‡µ ä¸ƒæµ· (æ—¥è¯­)"}
    ]
    emit('studio_data', {
        'models': scan_models(), 
        'current_id': CURRENT_MODEL['id'], 
        'voices': voices, 
        'backgrounds': scan_backgrounds(), 
        'current_bg': GLOBAL_STATE.get('current_background', '')
    })

@socketio.on('switch_model')
def on_sw(d):
    global CURRENT_MODEL
    t = next((m for m in scan_models() if m['id'] == d['id']), None)
    if t: 
        CURRENT_MODEL = t
        GLOBAL_STATE["current_model_id"] = t['id']
        save_state()
        init_chatroom()
        emit('model_switched', CURRENT_MODEL, to='lobby')

@socketio.on('switch_background')
def on_sw_bg(d):
    GLOBAL_STATE['current_background'] = d.get('name')
    save_state()
    emit('background_update', {'url': f"/static/backgrounds/{d.get('name')}" if d.get('name') else ""}, to='lobby')

@socketio.on('save_settings')
def on_sav(d):
    if not is_admin(request.sid): return
    global CURRENT_MODEL
    try: 
        d['scale']=float(d['scale'])
        d['x']=float(d['x'])
        d['y']=float(d['y'])
    except: pass
    updated = save_model_config(d['id'], d)
    if CURRENT_MODEL['id'] == d['id']: 
        CURRENT_MODEL.update(updated)
        init_chatroom()
        emit('model_switched', CURRENT_MODEL, to='lobby')
    emit('toast', {'text': 'âœ… è®¾ç½®å·²ä¿å­˜'})

@socketio.on('delete_model')
def on_del(d):
    if not is_admin(request.sid): return
    if d['id'] != CURRENT_MODEL['id']:
        shutil.rmtree(os.path.join(MODELS_DIR, d['id']), ignore_errors=True)
        emit('toast', {'text': 'ğŸ—‘ï¸ å·²åˆ é™¤'})
        on_get_data()

@socketio.on('download_model')
def on_dl(d):
    if not is_admin(request.sid): return
    name = d.get('name')
    emit('toast', {'text': f'ğŸš€ ä¸‹è½½ {name}...', 'type':'info'})
    socketio.start_background_task(bg_dl_task, name)

def bg_dl_task(name):
    u = f"https://github.com/Live2D/CubismWebSamples/trunk/Samples/Resources/{name}"
    t = os.path.join(MODELS_DIR, name.lower())
    shutil.rmtree(t, ignore_errors=True)
    os.makedirs(t, exist_ok=True)
    try:
        os.system(f"svn export --force -q {u} {t}")
        socketio.emit('toast', {'text': f'âœ… {name} ä¸‹è½½å®Œæˆ!'}, namespace='/')
    except: pass

if __name__ == '__main__':
    logging.info("Starting Pico AI Server...")
    socketio.run(app, host='0.0.0.0', port=5000)
